import csv
import json
import logging
import asyncio
import aiohttp
import ssl
import time
import os
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv, set_key
from urllib.parse import urlencode

# Load environment variables
load_dotenv()

async def login_to_ib():
    """Login to IntelligenceBank and update .env with response values."""
    # Get login credentials from environment
    platform_url = os.getenv('PLATFORM_URL')
    email = os.getenv('EMAIL')
    password = os.getenv('PASSWORD')
    api_v2_url = os.getenv('API_V2_URL')

    if not all([platform_url, email, password, api_v2_url]):
        logging.error("Missing login credentials. Please check your .env file.")
        logging.error("Required variables: PLATFORM_URL, EMAIL, PASSWORD, API_V2_URL")
        exit(1)

    # Prepare login request
    url = f"{api_v2_url}/webapp/1.0/login"
    data = {
        'p70': email,
        'p80': password,
        'p90': platform_url
    }
    headers = {'Content-Type': 'application/x-www-form-urlencoded'}

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(url, data=urlencode(data), headers=headers, ssl=False) as response:
                if response.status != 200:
                    logging.error(f"Login failed with status {response.status}")
                    exit(1)

                login_data = await response.json()
                
                # Update .env file with response values
                env_path = Path('.env')
                set_key(env_path, 'API_V3_URL', login_data['apiV3url'])
                set_key(env_path, 'CLIENT_ID', login_data['clientid'])
                set_key(env_path, 'SID', login_data['sid'])
                
                # Force reload environment variables
                os.environ['API_V3_URL'] = login_data['apiV3url']
                os.environ['CLIENT_ID'] = login_data['clientid']
                os.environ['SID'] = login_data['sid']
                
                logging.info(f"Successfully logged in and updated credentials: API_V3_URL={os.getenv('API_V3_URL')}, CLIENT_ID={os.getenv('CLIENT_ID')}, SID={os.getenv('SID')}")
                
    except Exception as e:
        logging.error(f"Login failed: {str(e)}")
        exit(1)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'update_resources_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)

# Rate limiting configuration
RATE_LIMIT = 600  # requests per minute
BATCH_SIZE = 10   # concurrent requests
RATE_LIMIT_PER_SECOND = RATE_LIMIT / 60

# Payload for the PUT request - THIS IS WHERE YOU CAN MAKE ADJUSTMENTS TO WHAT IS INCLUDED. See https://apidoc.intelligencebank.com/#62ff46b9-46ab-4460-a902-427168ab2742 for more details
payload = {
    "data": {
        "tags": [], # Only include as empty if you want to clear out existing tags
        "amaTags": {
            "objects": {
                "autoGen": False,
                "autoGeneratedTags": [], # Only include as empty if you want to clear out existing tags
            },
            "keywords": {
                "autoGen": False,
                "autoGeneratedTags": [] # Only include as empty if you want to clear out existing tags
            },
            "landmarks": {
                "autoGeneratedTags": [], # Only include as empty if you want to clear out existing tags
                "autoGen": False,
            },
            "faces": {
                "autoGeneratedTags": [], # Only include as empty if you want to clear out existing tags
                "autoGen": True
            }
        }
    }
}

class RateLimiter:
    def __init__(self, rate_limit_per_second):
        self.rate_limit = rate_limit_per_second
        self.tokens = rate_limit_per_second
        self.last_update = time.time()
        self.lock = asyncio.Lock()

    async def acquire(self):
        async with self.lock:
            now = time.time()
            time_passed = now - self.last_update
            self.tokens = min(self.rate_limit, self.tokens + time_passed * self.rate_limit)
            self.last_update = now

            if self.tokens < 1:
                sleep_time = (1 - self.tokens) / self.rate_limit
                await asyncio.sleep(sleep_time)
                self.tokens = 0
            else:
                self.tokens -= 1

class ResourceUpdater:
    def __init__(self):
        self.processed_file = Path('processed_ids.txt')
        self.errored_file = Path('errored_ids.txt')
        self.processed_ids = self._load_processed_ids()
        self.errored_ids = self._load_errored_ids()
        self.rate_limiter = RateLimiter(RATE_LIMIT_PER_SECOND)
        self.success_count = 0
        self.error_count = 0
        self.session = None
        self.start_time = None
        self.headers = {
            'Content-Type': 'application/json',
            'sid': os.getenv('SID')
        }

    def _load_processed_ids(self):
        if self.processed_file.exists():
            return set(self.processed_file.read_text().splitlines())
        return set()

    def _load_errored_ids(self):
        if self.errored_file.exists():
            return set(self.errored_file.read_text().splitlines())
        return set()

    def _save_processed_id(self, resource_id):
        with self.processed_file.open('a') as f:
            f.write(f"{resource_id}\n")

    def _save_errored_id(self, resource_id):
        with self.errored_file.open('a') as f:
            f.write(f"{resource_id}\n")

    def _log_progress(self, total_processed):
        if self.start_time is None:
            self.start_time = time.time()
            return

        elapsed_time = time.time() - self.start_time
        requests_per_second = total_processed / elapsed_time if elapsed_time > 0 else 0
        logging.info(f"Progress: {total_processed} processed, "
                    f"Rate: {requests_per_second:.2f} req/s, "
                    f"Success: {self.success_count}, "
                    f"Errors: {self.error_count}")

    async def handle_401_error(self):
        """Re-authenticate and update SID when session expires."""
        try:
            await login_to_ib()
            # Update headers with new SID
            self.headers['sid'] = os.getenv('SID')
            logging.info("Successfully re-authenticated after 401 error")
            return True
        except Exception as e:
            logging.error(f"Re-authentication failed: {str(e)}")
            return False

    async def update_resource(self, resource_id, retry_count=0):
        """Make PUT request to update a single resource."""
        if resource_id in self.processed_ids:
            logging.info(f"Skipping already processed Resource ID: {resource_id}")
            return None

        if resource_id in self.errored_ids:
            logging.info(f"Skipping previously errored Resource ID: {resource_id}")
            return None

        await self.rate_limiter.acquire()
        # Get latest environment variables
        api_v3_url = os.getenv('API_V3_URL')
        client_id = os.getenv('CLIENT_ID')
        url = f"{api_v3_url}/api/3.0.0/{client_id}/resource/{resource_id}?verbose=null"
        
        try:
            async with self.session.put(url, headers=self.headers, json=payload, ssl=False) as response:
                response_text = await response.text()
                if response.status == 200:
                    logging.info(f"Success - Resource ID: {resource_id} - Status: {response.status}")
                    self.success_count += 1
                    self._save_processed_id(resource_id)
                    return True
                elif response.status == 401 and retry_count < 3:
                    logging.info(f"Received 401 for Resource ID: {resource_id} - Attempting re-authentication")
                    if await self.handle_401_error():
                        # Retry the request with new SID
                        return await self.update_resource(resource_id, retry_count + 1)
                    else:
                        error_msg = "Re-authentication failed"
                        logging.error(f"Error - Resource ID: {resource_id} - {error_msg}")
                        self.error_count += 1
                        self._save_errored_id(resource_id)
                        return False
                else:
                    error_msg = f"Status Code: {response.status} - Response: {response_text}"
                    logging.error(f"Error - Resource ID: {resource_id} - {error_msg}")
                    self.error_count += 1
                    self._save_errored_id(resource_id)
                    return False
        except Exception as e:
            error_msg = f"Exception: {str(e)}"
            logging.error(f"Error - Resource ID: {resource_id} - {error_msg}")
            self.error_count += 1
            self._save_errored_id(resource_id)
            return False

    async def process_batch(self, batch):
        """Process a batch of resource IDs concurrently."""
        tasks = [self.update_resource(resource_id) for resource_id in batch]
        await asyncio.gather(*tasks)
        self._log_progress(self.success_count + self.error_count)

    async def run(self):
        """Main function to process the CSV file and update resources."""
        logging.info("Starting resource update process")
        if self.processed_ids:
            logging.info(f"Resuming from previous run. Already processed: {len(self.processed_ids)} resources")
        if self.errored_ids:
            logging.info(f"Found {len(self.errored_ids)} previously errored resources (will be skipped)")
        
        try:
            # Create SSL context that doesn't verify certificates
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            
            conn = aiohttp.TCPConnector(ssl=False)
            timeout = aiohttp.ClientTimeout(total=30)  # 30 seconds timeout
            
            async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:
                self.session = session
                batch = []
                
                with open('list.csv', 'r') as file:
                    csv_reader = csv.reader(file)
                    for row in csv_reader:
                        if row:  # Skip empty rows
                            resource_id = row[0].strip()
                            batch.append(resource_id)
                            
                            if len(batch) >= BATCH_SIZE:
                                await self.process_batch(batch)
                                batch = []
                    
                    # Process remaining resources
                    if batch:
                        await self.process_batch(batch)
        
        except FileNotFoundError:
            logging.error("list.csv file not found")
            return
        except Exception as e:
            logging.error(f"Unexpected error: {str(e)}")
            return
        finally:
            elapsed_time = time.time() - self.start_time if self.start_time else 0
            logging.info(
                f"Process completed - Successful updates: {self.success_count}, "
                f"Errors: {self.error_count}, "
                f"Total time: {elapsed_time:.2f} seconds, "
                f"Average rate: {(self.success_count + self.error_count) / elapsed_time:.2f} req/s"
            )

async def main():
    # Login first to get/update credentials
    await login_to_ib()
    
    # Validate required environment variables after login
    API_V3_URL = os.getenv('API_V3_URL')
    CLIENT_ID = os.getenv('CLIENT_ID')
    SID = os.getenv('SID')

    if not all([API_V3_URL, CLIENT_ID, SID]):
        logging.error("Missing required environment variables after login. This shouldn't happen.")
        logging.error("Required variables: API_V3_URL, CLIENT_ID, SID")
        exit(1)
    
    # Then proceed with resource updates
    updater = ResourceUpdater()
    await updater.run()

if __name__ == "__main__":
    asyncio.run(main())